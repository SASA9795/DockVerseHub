# File Location: labs/lab_04_logging_dashboard/logstash/pipelines/main.conf

input {
  # HTTP input for application logs
  http {
    port => 8080
    codec => json
    additional_codecs => {
      "application/json" => "json"
    }
  }
  
  # TCP input for structured logs  
  tcp {
    port => 5000
    codec => json_lines
  }
  
  # UDP input for syslog
  udp {
    port => 514
    codec => plain
  }
  
  # File input for log files
  file {
    path => "/var/log/containers/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
  }
  
  # Beats input
  beats {
    port => 5044
  }
}

filter {
  # Parse container logs
  if [log] {
    json {
      source => "log"
      target => "parsed_log"
    }
  }
  
  # Parse timestamp
  if [@timestamp] {
    date {
      match => [ "@timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd HH:mm:ss" ]
      target => "@timestamp"
    }
  }
  
  # Extract log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  } else if [message] {
    grok {
      match => { 
        "message" => "(?i)(?<level>DEBUG|INFO|WARN|WARNING|ERROR|FATAL|TRACE)" 
      }
    }
    if [level] {
      mutate {
        uppercase => [ "level" ]
      }
    }
  }
  
  # Parse HTTP access logs
  if [message] =~ /^\d+\.\d+\.\d+\.\d+/ {
    grok {
      match => { 
        "message" => "%{COMBINEDAPACHELOG}" 
      }
    }
    
    if [response] {
      mutate {
        convert => { "response" => "integer" }
      }
    }
    
    if [bytes] {
      mutate {
        convert => { "bytes" => "integer" }
      }
    }
    
    # Add response time if available
    if [request_time] {
      mutate {
        convert => { "request_time" => "float" }
      }
    }
  }
  
  # Parse JSON messages
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "json_data"
    }
  }
  
  # Extract service information
  if [container] and [container][name] {
    mutate {
      add_field => { "service" => "%{[container][name]}" }
    }
  } else if [fields] and [fields][service] {
    mutate {
      add_field => { "service" => "%{[fields][service]}" }
    }
  } else {
    mutate {
      add_field => { "service" => "unknown" }
    }
  }
  
  # Extract hostname
  if [host] and [host][name] {
    mutate {
      add_field => { "hostname" => "%{[host][name]}" }
    }
  }
  
  # Add environment tag
  mutate {
    add_field => { "environment" => "development" }
    add_tag => [ "dockversehub", "lab04" ]
  }
  
  # Clean up fields
  mutate {
    remove_field => [ "agent", "ecs", "input", "log" ]
  }
  
  # Handle parsing failures
  if "_grokparsefailure" in [tags] {
    mutate {
      add_field => { "grok_parse_failure" => "true" }
    }
  }
  
  if "_jsonparsefailure" in [tags] {
    mutate {
      add_field => { "json_parse_failure" => "true" }
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    template_name => "logs-template"
    template_pattern => "logs-*"
    template => "/usr/share/logstash/templates/logs-template.json"
  }
  
  # Output errors to separate index
  if [level] == "ERROR" or [level] == "FATAL" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Output HTTP access logs to separate index
  if [response] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "access-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output (comment out in production)
  if [service] == "debug" {
    stdout {
      codec => rubydebug
    }
  }
}