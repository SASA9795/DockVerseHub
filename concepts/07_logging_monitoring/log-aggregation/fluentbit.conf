# 07_logging_monitoring/log-aggregation/fluentbit.conf

[SERVICE]
    Flush         5
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf
    HTTP_Server   On
    HTTP_Listen   0.0.0.0
    HTTP_Port     2020
    storage.path  /var/log/flb-storage/
    storage.sync  normal
    storage.checksum off
    storage.backlog.mem_limit 5M

# Docker container logs input
[INPUT]
    Name              tail
    Path              /var/lib/docker/containers/*/*.log
    Parser            docker
    Tag               docker.*
    Refresh_Interval  5
    Mem_Buf_Limit     5MB
    Skip_Long_Lines   On
    Skip_Empty_Lines  On

# Application logs input
[INPUT]
    Name              tail
    Path              /var/log/app/*.log
    Parser            json
    Tag               app.*
    Refresh_Interval  5
    Mem_Buf_Limit     5MB

# System logs input
[INPUT]
    Name              systemd
    Tag               systemd.*
    Systemd_Filter    _SYSTEMD_UNIT=docker.service
    Read_From_Tail    On

# Forward input for other log shippers
[INPUT]
    Name   forward
    Listen 0.0.0.0
    Port   24224
    Tag    forward.*

# HTTP input for webhook logs
[INPUT]
    Name   http
    Listen 0.0.0.0
    Port   9880
    Tag    http.*

# Filters

# Parse Docker logs
[FILTER]
    Name                parser
    Match               docker.*
    Key_Name            log
    Parser              docker_multiline
    Reserve_Data        On
    Preserve_Key        On

# Add Kubernetes metadata (if running in K8s)
[FILTER]
    Name                kubernetes
    Match               docker.*
    Kube_URL            https://kubernetes.default.svc:443
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    Kube_Tag_Prefix     docker.var.log.containers.
    Merge_Log           On
    Merge_Log_Key       log_processed
    K8S-Logging.Parser  On
    K8S-Logging.Exclude Off

# JSON parsing filter
[FILTER]
    Name   parser
    Match  app.*
    Key_Name message
    Parser json
    Reserve_Data On

# Add hostname
[FILTER]
    Name   modify
    Match  *
    Add    hostname ${HOSTNAME}
    Add    environment ${ENVIRONMENT}
    Add    cluster ${CLUSTER_NAME}

# Grep filter to exclude noise
[FILTER]
    Name   grep
    Match  *
    Exclude log kubernetes.var.log.containers.fluent

# Record modifier
[FILTER]
    Name   record_modifier
    Match  *
    Record source fluent-bit
    Record pipeline_version 1.0

# Nest filter for structured logging
[FILTER]
    Name   nest
    Match  docker.*
    Operation nest
    Wildcard container_*
    Nest_under container
    Remove_prefix container_

# Lua script for custom processing
[FILTER]
    Name   lua
    Match  *
    Script /fluent-bit/scripts/enhance_logs.lua
    Call   enhance_logs

# Output configurations

# Primary output to Elasticsearch
[OUTPUT]
    Name            es
    Match           *
    Host            elasticsearch
    Port            9200
    Index           fluentbit
    Type            _doc
    Logstash_Format On
    Logstash_Prefix fluentbit
    Logstash_DateFormat %Y.%m.%d
    Include_Tag_Key On
    Tag_Key         @tag
    Time_Key        @timestamp
    Time_Key_Format %Y-%m-%dT%H:%M:%S
    Generate_ID     On
    Workers         1
    
    # Retry configuration
    Retry_Limit     3
    
    # Buffer configuration
    storage.total_limit_size 5M

# Secondary output to Logstash
[OUTPUT]
    Name  forward
    Match *
    Host  logstash
    Port  24224
    
    # Shared key for security
    Shared_Key secret_string
    
    # Time format
    Time_as_Integer On

# File output for debugging
[OUTPUT]
    Name  file
    Match docker.*
    Path  /var/log/fluentbit/
    File  docker.log
    Format json_lines

# HTTP output for webhooks
[OUTPUT]
    Name  http
    Match error.*
    Host  webhook-receiver
    Port  8080
    URI   /alerts
    Format json
    json_date_key timestamp
    json_date_format iso8601

# S3 output for long-term storage
[OUTPUT]
    Name                         s3
    Match                        *
    bucket                       my-log-bucket
    region                       us-east-1
    total_file_size              50M
    upload_timeout               10m
    use_put_object               On
    s3_key_format                /year=%Y/month=%m/day=%d/hour=%H/%{hostname}-%{tag}-%{index}
    s3_key_format_tag_delimiters .-
    
    # Compression
    compression                  gzip